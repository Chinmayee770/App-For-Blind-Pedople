# Mobile App for Visually Impaired People

## Project Overview
This project focuses on developing a **mobile application** to assist **visually impaired individuals** in performing daily activities more efficiently. The application integrates **voice commands, object detection, navigation support, and other essential features** to improve accessibility.

---

## 📌 Abstract
Visually impaired people face multiple challenges in their daily lives, such as navigating unfamiliar environments, reading printed text, and recognizing objects. Our mobile application aims to address these difficulties using **AI-based voice assistance** and **object detection technologies**. The app provides features like text reading, navigation support, weather updates, and a calculator, making day-to-day tasks easier for visually impaired users.

---

## 📌 Problem Statement
Many visually impaired individuals struggle with recognizing objects, reading documents, and navigating their surroundings. Existing solutions are either expensive or limited in scope. Our proposed mobile application provides an **affordable, user-friendly, and efficient** way for visually impaired individuals to gain more independence in their daily activities.

---

## 🎯 Objectives
- Develop an intuitive voice-based mobile application.
- Implement **object detection, text-to-speech, and navigation assistance**.
- Provide an easy-to-use interface for visually impaired individuals.
- Ensure **real-time processing** for efficient responses.
- Enhance accessibility and independence for users.

---

## 🛠️ Methodology
The system follows a **voice-command-based workflow**, where:
1. The user provides a voice input.
2. The voice assistant processes the command.
3. The interpreter identifies the task and redirects it to the appropriate module.
4. The system retrieves relevant information and provides feedback to the user.

---

## 🏗️ System Design
The app consists of the following core modules:
- **User Interaction**: Voice input processing and response generation.
- **Read Module**: Recognizes and reads text aloud.
- **Object Detection Module**: Identifies objects using a mobile camera.
- **Navigation Module**: Provides directional assistance.
- **Weather Module**: Gives real-time weather updates.
- **Calculator Module**: Performs basic calculations via voice input.

### UML Diagram
The app follows a structured **UML sequence and class diagram**, outlining the interaction between components such as **voice assistant, interpreter, and task execution models**.

---

## 📊 Results and Discussions
- The app successfully detects objects and reads texts aloud.
- It provides accurate navigation assistance using **voice commands**.
- The AI-based voice assistant responds efficiently to user queries.
- The user interface is designed to be simple, ensuring ease of use for visually impaired individuals.
- Testing results indicate improved user independence and accessibility.

---

## 🔍 Conclusions / Novelty Findings
- **Voice-driven UI** improves accessibility for visually impaired users.
- **Real-time object detection** enhances independence in daily tasks.
- The integration of **multiple assistive features** in a single app makes it a comprehensive tool.
- The app provides an **affordable alternative** to existing commercial solutions.

---

## 🔧 Future Enhancements
- **Integration with smart wearables** for better user experience.
- **Multi-language support** to cater to a diverse audience.
- **AI-based scene understanding** for more precise navigation assistance.
- **Cloud-based data storage** for personalized user preferences.

---
